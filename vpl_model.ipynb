{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class SensoryNeurons(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_neurons, in_dim = 1, plastic = True, params = (5, -2.5)):\n",
    "        super(SensoryNeurons, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.plastic = plastic\n",
    "        self.params = params\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim,self.num_neurons, bias = True)\n",
    "        self.resp_func = nn.Sigmoid()\n",
    "\n",
    "        if not self.plastic:\n",
    "            self.set_linear_weights()\n",
    "            self.linear.weight.requires_grad = False\n",
    "        \n",
    "    def set_linear_weights(self):\n",
    "        \n",
    "        self.linear.weight = torch.nn.Parameter(data = self.params[0] + 0.2*torch.randn(self.num_neurons,1), requires_grad = False)\n",
    "        self.linear.bias = torch.nn.Parameter(data = self.params[1] + 0.2*torch.randn(self.num_neurons), requires_grad = False)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = self.resp_func(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class SensoryPopulation(nn.Module):\n",
    "    def __init__(self, num_neurons, plastic = True, population_ratio = 0.5):\n",
    "        super(SensoryPopulation, self).__init__()\n",
    "        \n",
    "        self.num_neurons = num_neurons\n",
    "        self.plastic = plastic\n",
    "        self.num_neurons_group1 = int(self.num_neurons * population_ratio)\n",
    "        self.num_neurons_group2 = int(self.num_neurons * (1 - population_ratio))\n",
    "        \n",
    "        self.sensory_neurons_1 = SensoryNeurons(num_neurons = self.num_neurons_group1, in_dim = 1, plastic = self.plastic, params = (5, -2.5))\n",
    "        self.sensory_neurons_2 = SensoryNeurons(num_neurons = self.num_neurons_group2, in_dim = 1, plastic = self.plastic, params = (-5, -2.5))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.sensory_neurons_1(x)\n",
    "        x2 = self.sensory_neurons_2(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2),dim = 1)       \n",
    "        \n",
    "        return out\n",
    "            \n",
    "        \n",
    "    \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self,num_classes = 2, in_dim = 10):\n",
    "        super(Readout, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.in_dim = in_dim\n",
    "        \n",
    "        self.readout_layer = nn.Linear(self.in_dim, self.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.readout_layer(x)\n",
    "    \n",
    "    \n",
    "class Sensorimotor(nn.Module):\n",
    "    def __init__(self, num_sensory_neurons = 10, sensory_plastic = True, sensory_pop_ratio = 0.5, num_classes = 2):\n",
    "        super(Sensorimotor, self).__init__()\n",
    "        \n",
    "        self.sensory_pop = SensoryPopulation(num_neurons = num_sensory_neurons, plastic = sensory_plastic, population_ratio = sensory_pop_ratio)\n",
    "        self.readout = Readout(num_classes = num_classes, in_dim = num_sensory_neurons)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        sensory_out = self.sensory_pop(x)\n",
    "        y = self.readout(sensory_out)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Stimulus(data.DataLoader):\n",
    "    def __init__(self, min_coherence = 0.8, max_coherence = 1):\n",
    "        \n",
    "        self.min_coherence = min_coherence\n",
    "        self.max_coherence = max_coherence\n",
    "        \n",
    "        self.NUM_SAMPLPES_PER_CATEGORY = 1000\n",
    "        \n",
    "        data1 = torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        data2 = -torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        target1 = torch.zeros(data1.shape, dtype = int)\n",
    "        target2 = torch.ones(data2.shape, dtype = int)\n",
    "        \n",
    "        self.data = torch.cat((data1, data2), dim = 0).unsqueeze(0).t()\n",
    "        self.target = torch.cat((target1, target2), dim = 0).unsqueeze(0).t()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        return (self.data[index], self.target[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "\n",
    "def main(num_epochs = 1000, lr = 1e-1, batch_size = 100):\n",
    "    \n",
    "    model = Sensorimotor(num_sensory_neurons = 10, sensory_plastic = False, sensory_pop_ratio = 0.5, num_classes = 2)\n",
    "    \n",
    "    print('\\n===========Check Grad============')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.requires_grad)\n",
    "    print('=================================\\n')    \n",
    "    \n",
    "    params = model.parameters()\n",
    "    \n",
    "    optimizer = optim.SGD(params, lr=lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    dataset_train = Stimulus(min_coherence = 0, max_coherence = 0.2)\n",
    "    dataset_valid = Stimulus(min_coherence = 0, max_coherence = 0.2)\n",
    "    \n",
    "    sampler_train = data.RandomSampler(dataset_train)\n",
    "    train_dl = data.DataLoader(dataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_train,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    sampler_valid = data.RandomSampler(dataset_valid)\n",
    "    valid_dl = data.DataLoader(dataset_valid,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_valid,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "\n",
    "\n",
    "    all_loss = []\n",
    "    all_loss_valid = []\n",
    "    for epoch in range(num_epochs):\n",
    "        Loss = 0\n",
    "        \n",
    "        for stimulus, target in train_dl:\n",
    "            \n",
    "            decision = model(stimulus)\n",
    "            \n",
    "            L = loss(decision, target.squeeze())\n",
    "            Loss += L/len(train_dl)\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del L\n",
    "            \n",
    "            \n",
    "        Loss_valid = 0\n",
    "        \n",
    "        for stimulus, target in valid_dl:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                decision = model(stimulus)\n",
    "\n",
    "                L = loss(decision, target.squeeze())\n",
    "                Loss_valid += L/len(train_dl)\n",
    "                \n",
    "\n",
    "                del L\n",
    "        \n",
    "        all_loss.append(Loss)\n",
    "        all_loss_valid.append(Loss_valid)\n",
    "        \n",
    "        \n",
    "        # print(f'epoch {epoch},   training Loss = {Loss},   validation Loss = {Loss_valid}')\n",
    "    return all_loss, all_loss_valid\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========Check Grad============\n",
      "sensory_pop.sensory_neurons_1.linear.weight True\n",
      "sensory_pop.sensory_neurons_1.linear.bias True\n",
      "sensory_pop.sensory_neurons_2.linear.weight True\n",
      "sensory_pop.sensory_neurons_2.linear.bias True\n",
      "readout.readout_layer.weight True\n",
      "readout.readout_layer.bias True\n",
      "=================================\n",
      "\n",
      "Final train loss = 0.01921575888991356,    valid loss = 0.01979891024529934 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "lr = 1\n",
    "batch_size = 100\n",
    "\n",
    "loss, loss_valid = main(num_epochs = num_epochs, lr = lr, batch_size = batch_size)\n",
    "print(f'Final train loss = {loss[-1]},    valid loss = {loss_valid[-1]} \\n')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(np.arange(0,num_epochs),loss)\n",
    "plt.plot(np.arange(0,num_epochs),loss_valid)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation loss for different ranges of min and max coherences:\n",
    "Sensory plasticity OFF:\n",
    "\n",
    "0-0.2 --> Final train loss = 0.0577029325067997,    valid loss = 0.05982879921793938 \n",
    "\n",
    "0.2-0.4 --> Final train loss = 0.046443745493888855,    valid loss = 0.04600318521261215\n",
    "\n",
    "0.4-0.6 --> Final train loss = 0.04211679473519325,    valid loss = 0.04063735902309418\n",
    "\n",
    "0.6-0.8 --> Final train loss = 0.05295262113213539,    valid loss = 0.051513705402612686\n",
    "\n",
    "0.8-1 --> Final train loss = 0.07020311057567596,    valid loss = 0.07754290103912354\n",
    "\n",
    "For a fixed sensory neuron parameter, there's an optimal range of input coherences. Suprising that it doesn't perform as well for high coherences. \n",
    "\n",
    "Sensory plasticity ON:\n",
    "\n",
    "0-0.2 --> Final train loss = 0.01921575888991356,    valid loss = 0.01979891024529934\n",
    "\n",
    "0.2-0.4 --> Final train loss = 0.016101516783237457,    valid loss = 0.01750151626765728\n",
    "\n",
    "0.4-0.6 --> Final train loss = 0.016150424256920815,    valid loss = 0.018810011446475983\n",
    "\n",
    "0.6-0.8 --> Final train loss = 0.020135795697569847,    valid loss = 0.0218290798366069\n",
    "\n",
    "0.8-1 --> Final train loss = 0.03612269461154938,    valid loss = 0.018730392679572105\n",
    "\n",
    "With sensory plasticity, all the ranges reach the same performance. \n",
    "\n",
    "However, as soon as we change the range of train and validation coherences, the validation loss increases throughout training, meaning that the model can't generalize out of the training coherence ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
