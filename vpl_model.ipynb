{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class SensoryNeurons(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_neurons, in_dim = 1, plastic = True, params = (5, -2.5)):\n",
    "        super(SensoryNeurons, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.plastic = plastic\n",
    "        self.params = params\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim,self.num_neurons, bias = True)\n",
    "        self.resp_func = nn.Sigmoid()\n",
    "\n",
    "        if not self.plastic:\n",
    "            self.set_linear_weights()\n",
    "            self.linear.weight.requires_grad = False\n",
    "        \n",
    "    def set_linear_weights(self):\n",
    "        \n",
    "        self.linear.weight = torch.nn.Parameter(data = self.params[0] + 0.2*torch.randn(self.num_neurons,1), requires_grad = False)\n",
    "        self.linear.bias = torch.nn.Parameter(data = self.params[1] + 0.2*torch.randn(self.num_neurons), requires_grad = False)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = self.resp_func(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class SensoryPopulation(nn.Module):\n",
    "    def __init__(self, num_neurons, plastic = True, population_ratio = 0.5):\n",
    "        super(SensoryPopulation, self).__init__()\n",
    "        \n",
    "        self.num_neurons = num_neurons\n",
    "        self.plastic = plastic\n",
    "        self.num_neurons_group1 = round(self.num_neurons * population_ratio)\n",
    "        self.num_neurons_group2 = round(self.num_neurons * (1.0 - population_ratio))\n",
    "        self.sensory_neurons_1 = SensoryNeurons(num_neurons = self.num_neurons_group1, in_dim = 1, plastic = self.plastic, params = (5, -2.5))\n",
    "        self.sensory_neurons_2 = SensoryNeurons(num_neurons = self.num_neurons_group2, in_dim = 1, plastic = self.plastic, params = (-5, -2.5))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.sensory_neurons_1(x)\n",
    "        x2 = self.sensory_neurons_2(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2),dim = 1)       \n",
    "        \n",
    "        return out\n",
    "            \n",
    "        \n",
    "    \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self,num_classes = 2, in_dim = 10):\n",
    "        super(Readout, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.in_dim = in_dim\n",
    "        \n",
    "        self.readout_layer = nn.Linear(self.in_dim, self.num_classes, bias = True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.readout_layer(x)\n",
    "    \n",
    "    \n",
    "class Sensorimotor(nn.Module):\n",
    "    def __init__(self, num_sensory_neurons = 10, sensory_plastic = True, sensory_pop_ratio = 0.5, num_classes = 2):\n",
    "        super(Sensorimotor, self).__init__()\n",
    "        \n",
    "        self.sensory_pop = SensoryPopulation(num_neurons = num_sensory_neurons, plastic = sensory_plastic, population_ratio = sensory_pop_ratio)\n",
    "        self.readout = Readout(num_classes = num_classes, in_dim = num_sensory_neurons)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        sensory_out = self.sensory_pop(x)\n",
    "        y = self.readout(sensory_out)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Stimulus(data.DataLoader):\n",
    "    def __init__(self, min_coherence = 0.8, max_coherence = 1):\n",
    "        \n",
    "        self.min_coherence = min_coherence\n",
    "        self.max_coherence = max_coherence\n",
    "        \n",
    "        self.NUM_SAMPLPES_PER_CATEGORY = 1000\n",
    "        \n",
    "        data1 = torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        data2 = -torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        target1 = torch.zeros(data1.shape, dtype = int)\n",
    "        target2 = torch.ones(data2.shape, dtype = int)\n",
    "        \n",
    "        self.data = torch.cat((data1, data2), dim = 0).unsqueeze(0).t()\n",
    "        self.target = torch.cat((target1, target2), dim = 0).unsqueeze(0).t()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        return (self.data[index], self.target[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class ConfusionMeter(object):\n",
    "    '''compute and show confusion matrix'''\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.mat = np.zeros((num_class, num_class))\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "\n",
    "    def update(self, pred, tar):\n",
    "        pred, tar = pred.cpu().numpy(), tar.cpu().numpy()\n",
    "        pred = np.squeeze(pred)\n",
    "        tar = np.squeeze(tar)\n",
    "        for p,t in zip(pred.flat, tar.flat):\n",
    "            self.mat[p][t] += 1\n",
    "\n",
    "    def print_mat(self):\n",
    "        print('Confusion Matrix: (target in columns)')\n",
    "        print(self.mat)\n",
    "\n",
    "    def plot_mat(self, path, dictionary=None, annotate=False):\n",
    "        plt.figure(dpi=600)\n",
    "        plt.imshow(self.mat,\n",
    "            cmap=plt.cm.jet,\n",
    "            interpolation=None,\n",
    "            extent=(0.5, np.shape(self.mat)[0]+0.5, np.shape(self.mat)[1]+0.5, 0.5))\n",
    "        width, height = self.mat.shape\n",
    "        if annotate:\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    plt.annotate(str(int(self.mat[x][y])), xy=(y+1, x+1),\n",
    "                                 horizontalalignment='center',\n",
    "                                 verticalalignment='center',\n",
    "                                 fontsize=8)\n",
    "\n",
    "        if dictionary is not None:\n",
    "            plt.xticks([i+1 for i in range(width)],\n",
    "                       [dictionary[i] for i in range(width)],\n",
    "                       rotation='vertical')\n",
    "            plt.yticks([i+1 for i in range(height)],\n",
    "                       [dictionary[i] for i in range(height)])\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Prediction')\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, format='svg')\n",
    "        plt.clf()\n",
    "\n",
    "        # for i in range(width):\n",
    "        #     if np.sum(self.mat[i,:]) != 0:\n",
    "        #         self.precision.append(self.mat[i,i] / np.sum(self.mat[i,:]))\n",
    "        #     if np.sum(self.mat[:,i]) != 0:\n",
    "        #         self.recall.append(self.mat[i,i] / np.sum(self.mat[:,i]))\n",
    "        # print('Average Precision: %0.4f' % np.mean(self.precision))\n",
    "        # print('Average Recall: %0.4f' % np.mean(self.recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "\n",
    "def main(num_epochs = 1000, lr = 1e-1, batch_size = 100, learning_rule = 'backprop'): # learning_rule can be 'backprop' or 'global_gain'\n",
    "    \n",
    "    model = Sensorimotor(num_sensory_neurons = 100, \n",
    "                         sensory_plastic = False, \n",
    "                         sensory_pop_ratio = 0.5,\n",
    "                         num_classes = 2)\n",
    "    print(model)\n",
    "    print('\\n===========Check Grad============')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.requires_grad)\n",
    "    print('=================================\\n')    \n",
    "    \n",
    "    params = model.parameters()\n",
    "    \n",
    "    \n",
    "    optimizer = optim.SGD(params, lr=lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    dataset_train = Stimulus(min_coherence = 0.02, max_coherence = 0.05) # set the range of coherences\n",
    "    dataset_valid = Stimulus(min_coherence = 0.02, max_coherence = 0.05)\n",
    "    \n",
    "    sampler_train = data.RandomSampler(dataset_train)\n",
    "    train_dl = data.DataLoader(dataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_train,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    sampler_valid = data.RandomSampler(dataset_valid)\n",
    "    valid_dl = data.DataLoader(dataset_valid,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_valid,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "\n",
    "\n",
    "    all_loss = []\n",
    "    all_loss_valid = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        Loss = 0\n",
    "        \n",
    "        for stimulus, target in train_dl:\n",
    "            \n",
    "            decision = model(stimulus)\n",
    "            L = loss(decision, target.squeeze())\n",
    "            Loss += L/len(train_dl)\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()      \n",
    "            \n",
    "            if learing_rule == 'global_gain':\n",
    "                model = personalized_backward(model,stimulus, target, method='global_gain')\n",
    "                    \n",
    "            optimizer.step()\n",
    "            del L\n",
    "            \n",
    "            \n",
    "        Loss_valid = 0\n",
    "        conf_mat = ConfusionMeter(num_class=2)\n",
    "        i = 0\n",
    "        for stimulus, target in valid_dl:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                decision = model(stimulus)\n",
    "                \n",
    "                pred = decision.clone()\n",
    "\n",
    "                \n",
    "                decision_copy = decision.clone()\n",
    "                pred = target.clone()\n",
    "                idx1 = decision_copy[:,1] < decision_copy[:,0]\n",
    "                idx2 = decision_copy[:,1] >= decision_copy[:,0]\n",
    "                pred[idx1] = 0\n",
    "                pred[idx2] = 1\n",
    "\n",
    "                target_copy = target.squeeze().int()\n",
    "                conf_mat.update(pred.int(),target_copy)\n",
    "                del pred\n",
    "                L = loss(decision, target.squeeze())\n",
    "                Loss_valid += L/len(train_dl)\n",
    "                \n",
    "#                 \n",
    "\n",
    "                del L\n",
    "        if epoch == 0:\n",
    "            conf_mat.print_mat()\n",
    "            \n",
    "        all_loss.append(Loss)\n",
    "        all_loss_valid.append(Loss_valid)\n",
    "        \n",
    "    conf_mat.print_mat()\n",
    "        # print(f'epoch {epoch},   training Loss = {Loss},   validation Loss = {Loss_valid}')\n",
    "    return all_loss, all_loss_valid, model\n",
    "            \n",
    "            \n",
    "def personalized_backward(model, stimulus, target, method = 'global_gain'):\n",
    "    \n",
    "    if method == 'global_gain': \n",
    "        # only adds to the weight value:  if weight is negative (positive) adds a negative (positive) value \n",
    "        for n,p in model.named_parameters():\n",
    "\n",
    "            if p.requires_grad:\n",
    "#                 print(f'{n}, mean = {p.mean()}, std = {p.std()}')\n",
    "                p_sign = p.clone()\n",
    "                p_sign[p_sign>0] = 1\n",
    "                p_sign[p_sign<0] = -1\n",
    "                p.grad = 1e-1*torch.ones((p.grad.shape),requires_grad=True)*p_sign\n",
    "    \n",
    "    if method == 'hebbian': \n",
    "        # this is not working yet: the dimensions of output gradient do not match\n",
    "        # p.grad dimensions is num_sensory_neurons by 2 but a times target gives num_sensory_neurons by 1 \n",
    "        # this is mainly because the output of the readout layer is set up for cross-entropy loss (num_sensory_neurons by 2)\n",
    "        # we can set it up for hebbian learning with num_sensory_neurons by 1\n",
    "        for n,p in model.named_parameters():\n",
    "            \n",
    "            if 'readout' in n:\n",
    "                a = model.sensory_pop(stimulus)\n",
    "                test = a * target\n",
    "                p.grad = a * target\n",
    "                \n",
    "                \n",
    "        \n",
    "    return model\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensorimotor(\n",
      "  (sensory_pop): SensoryPopulation(\n",
      "    (sensory_neurons_1): SensoryNeurons(\n",
      "      (linear): Linear(in_features=1, out_features=50, bias=True)\n",
      "      (resp_func): Sigmoid()\n",
      "    )\n",
      "    (sensory_neurons_2): SensoryNeurons(\n",
      "      (linear): Linear(in_features=1, out_features=50, bias=True)\n",
      "      (resp_func): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (readout): Readout(\n",
      "    (readout_layer): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "===========Check Grad============\n",
      "sensory_pop.sensory_neurons_1.linear.weight False\n",
      "sensory_pop.sensory_neurons_1.linear.bias False\n",
      "sensory_pop.sensory_neurons_2.linear.weight False\n",
      "sensory_pop.sensory_neurons_2.linear.bias False\n",
      "readout.readout_layer.weight True\n",
      "readout.readout_layer.bias True\n",
      "=================================\n",
      "\n",
      "Confusion Matrix: (target in columns)\n",
      "[[   0.    0.]\n",
      " [1000. 1000.]]\n",
      "Confusion Matrix: (target in columns)\n",
      "[[   0.    0.]\n",
      " [1000. 1000.]]\n",
      "Final train loss = 0.6930516958236694,    valid loss = 0.6933578848838806 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "lr = 1e-1\n",
    "batch_size = 100\n",
    "\n",
    "loss, loss_valid, model = main(num_epochs = num_epochs, lr = lr, batch_size = batch_size)\n",
    "print(f'Final train loss = {loss[-1]},    valid loss = {loss_valid[-1]} \\n')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(np.arange(0,num_epochs),loss)\n",
    "plt.plot(np.arange(0,num_epochs),loss_valid)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(model.readout.readout_layer.weight.detach())\n",
    "\n",
    "# plt.scatter(torch.cat((model.sensory_pop.sensory_neurons_1.linear.weight,model.sensory_pop.sensory_neurons_2.linear.weight),dim=0).detach(),\n",
    "#             model.readout.readout_layer.weight[0,:].detach())\n",
    "plt.scatter(model.sensory_pop.sensory_neurons_1.linear.weight.detach(),\n",
    "            model.readout.readout_layer.weight[0,0:50].detach(),color='r')\n",
    "plt.scatter(model.sensory_pop.sensory_neurons_2.linear.weight.detach(),\n",
    "            model.readout.readout_layer.weight[0,50:100].detach(),color='b')\n",
    "plt.ylabel('readout weight',fontsize=15)\n",
    "plt.xlabel('sigmoid weight',fontsize=15)\n",
    "plt.grid('both')\n",
    "plt.savefig('/Users/shahab/Desktop/Figs/VPL/sigW_vs_readW.png')\n",
    "plt.show()\n",
    "# plt.scatter(torch.cat((model.sensory_pop.sensory_neurons_1.linear.bias,model.sensory_pop.sensory_neurons_2.linear.bias),dim=0).detach(),\n",
    "#             model.readout.readout_layer.weight[0,:].detach())\n",
    "plt.scatter(model.sensory_pop.sensory_neurons_1.linear.bias.detach(),\n",
    "            model.readout.readout_layer.weight[0,0:50].detach(),color='r')\n",
    "plt.scatter(model.sensory_pop.sensory_neurons_2.linear.bias.detach(),\n",
    "            model.readout.readout_layer.weight[0,50:100].detach(),color='b')\n",
    "plt.ylabel('readout weight',fontsize=15)\n",
    "plt.xlabel('sigmoid bias',fontsize=15)\n",
    "plt.grid('both')\n",
    "plt.savefig('/Users/shahab/Desktop/Figs/VPL/sigB_vs_readW.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [2., 3.]])\n",
      "tensor([[ 5., 10.],\n",
      "        [10., 15.]])\n"
     ]
    }
   ],
   "source": [
    "ttt = torch.Tensor([[1,2],[2,3]])\n",
    "aaa = torch.Tensor([[5],[5]])\n",
    "print(ttt)\n",
    "ttt = ttt * aaa\n",
    "print(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
