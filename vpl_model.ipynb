{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class SensoryNeurons(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_neurons, in_dim = 1, plastic = True, params = (5, -2.5)):\n",
    "        super(SensoryNeurons, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.plastic = plastic\n",
    "        self.params = params\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim,self.num_neurons, bias = True)\n",
    "        self.resp_func = nn.Sigmoid()\n",
    "\n",
    "        if not self.plastic:\n",
    "            self.set_linear_weights()\n",
    "            self.linear.weight.requires_grad = False\n",
    "        \n",
    "    def set_linear_weights(self):\n",
    "        \n",
    "        self.linear.weight = torch.nn.Parameter(data = self.params[0] + 0.2*torch.randn(self.num_neurons,1), requires_grad = False)\n",
    "        self.linear.bias = torch.nn.Parameter(data = self.params[1] + 0.2*torch.randn(self.num_neurons), requires_grad = False)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = self.resp_func(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class SensoryPopulation(nn.Module):\n",
    "    def __init__(self, num_neurons, plastic = True, population_ratio = 0.5):\n",
    "        super(SensoryPopulation, self).__init__()\n",
    "        \n",
    "        self.num_neurons = num_neurons\n",
    "        self.plastic = plastic\n",
    "        self.num_neurons_group1 = round(self.num_neurons * population_ratio)\n",
    "        self.num_neurons_group2 = round(self.num_neurons * (1.0 - population_ratio))\n",
    "        self.sensory_neurons_1 = SensoryNeurons(num_neurons = self.num_neurons_group1, in_dim = 1, plastic = self.plastic, params = (5, -2.5))\n",
    "        self.sensory_neurons_2 = SensoryNeurons(num_neurons = self.num_neurons_group2, in_dim = 1, plastic = self.plastic, params = (-5, 2.5))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.sensory_neurons_1(x)\n",
    "        x2 = self.sensory_neurons_2(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2),dim = 1)       \n",
    "        \n",
    "        return out\n",
    "            \n",
    "        \n",
    "    \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self,num_classes = 2, in_dim = 10):\n",
    "        super(Readout, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.in_dim = in_dim\n",
    "        \n",
    "        self.readout_layer = nn.Linear(self.in_dim, self.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.readout_layer(x)\n",
    "    \n",
    "    \n",
    "class Sensorimotor(nn.Module):\n",
    "    def __init__(self, num_sensory_neurons = 10, sensory_plastic = True, sensory_pop_ratio = 0.5, num_classes = 2):\n",
    "        super(Sensorimotor, self).__init__()\n",
    "        \n",
    "        self.sensory_pop = SensoryPopulation(num_neurons = num_sensory_neurons, plastic = sensory_plastic, population_ratio = sensory_pop_ratio)\n",
    "        self.readout = Readout(num_classes = num_classes, in_dim = num_sensory_neurons)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        sensory_out = self.sensory_pop(x)\n",
    "        y = self.readout(sensory_out)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Stimulus(data.DataLoader):\n",
    "    def __init__(self, min_coherence = 0.8, max_coherence = 1):\n",
    "        \n",
    "        self.min_coherence = min_coherence\n",
    "        self.max_coherence = max_coherence\n",
    "        \n",
    "        self.NUM_SAMPLPES_PER_CATEGORY = 1000\n",
    "        \n",
    "        data1 = torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        data2 = -torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        target1 = torch.zeros(data1.shape, dtype = int)\n",
    "        target2 = torch.ones(data2.shape, dtype = int)\n",
    "        \n",
    "        self.data = torch.cat((data1, data2), dim = 0).unsqueeze(0).t()\n",
    "        self.target = torch.cat((target1, target2), dim = 0).unsqueeze(0).t()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        return (self.data[index], self.target[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ConfusionMeter(object):\n",
    "    '''compute and show confusion matrix'''\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.mat = np.zeros((num_class, num_class))\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "\n",
    "    def update(self, pred, tar):\n",
    "        pred, tar = pred.cpu().numpy(), tar.cpu().numpy()\n",
    "        pred = np.squeeze(pred)\n",
    "        tar = np.squeeze(tar)\n",
    "        for p,t in zip(pred.flat, tar.flat):\n",
    "            self.mat[p][t] += 1\n",
    "\n",
    "    def print_mat(self):\n",
    "        print('Confusion Matrix: (target in columns)')\n",
    "        print(self.mat)\n",
    "\n",
    "    def plot_mat(self, path, dictionary=None, annotate=False):\n",
    "        plt.figure(dpi=600)\n",
    "        plt.imshow(self.mat,\n",
    "            cmap=plt.cm.jet,\n",
    "            interpolation=None,\n",
    "            extent=(0.5, np.shape(self.mat)[0]+0.5, np.shape(self.mat)[1]+0.5, 0.5))\n",
    "        width, height = self.mat.shape\n",
    "        if annotate:\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    plt.annotate(str(int(self.mat[x][y])), xy=(y+1, x+1),\n",
    "                                 horizontalalignment='center',\n",
    "                                 verticalalignment='center',\n",
    "                                 fontsize=8)\n",
    "\n",
    "        if dictionary is not None:\n",
    "            plt.xticks([i+1 for i in range(width)],\n",
    "                       [dictionary[i] for i in range(width)],\n",
    "                       rotation='vertical')\n",
    "            plt.yticks([i+1 for i in range(height)],\n",
    "                       [dictionary[i] for i in range(height)])\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Prediction')\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, format='svg')\n",
    "        plt.clf()\n",
    "\n",
    "        # for i in range(width):\n",
    "        #     if np.sum(self.mat[i,:]) != 0:\n",
    "        #         self.precision.append(self.mat[i,i] / np.sum(self.mat[i,:]))\n",
    "        #     if np.sum(self.mat[:,i]) != 0:\n",
    "        #         self.recall.append(self.mat[i,i] / np.sum(self.mat[:,i]))\n",
    "        # print('Average Precision: %0.4f' % np.mean(self.precision))\n",
    "        # print('Average Recall: %0.4f' % np.mean(self.recall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "\n",
    "def main(num_epochs = 1000, lr = 1e-1, batch_size = 100):\n",
    "    \n",
    "    model = Sensorimotor(num_sensory_neurons = 100, \n",
    "                         sensory_plastic = False, \n",
    "                         sensory_pop_ratio = 0.2,\n",
    "                         num_classes = 2)\n",
    "    \n",
    "    print('\\n===========Check Grad============')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.requires_grad)\n",
    "    print('=================================\\n')    \n",
    "    \n",
    "    params = model.parameters()\n",
    "    \n",
    "    optimizer = optim.SGD(params, lr=lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    dataset_train = Stimulus(min_coherence = 0.6, max_coherence = 0.8) # set the range of coherences\n",
    "    dataset_valid = Stimulus(min_coherence = 0.6, max_coherence = 0.8)\n",
    "    \n",
    "    sampler_train = data.RandomSampler(dataset_train)\n",
    "    train_dl = data.DataLoader(dataset_train,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_train,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    sampler_valid = data.RandomSampler(dataset_valid)\n",
    "    valid_dl = data.DataLoader(dataset_valid,\n",
    "                             batch_size=batch_size,\n",
    "                             sampler=sampler_valid,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "\n",
    "\n",
    "    all_loss = []\n",
    "    all_loss_valid = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        Loss = 0\n",
    "        \n",
    "        for stimulus, target in train_dl:\n",
    "            \n",
    "            decision = model(stimulus)\n",
    "            L = loss(decision, target.squeeze())\n",
    "            Loss += L/len(train_dl)\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del L\n",
    "            \n",
    "            \n",
    "        Loss_valid = 0\n",
    "        conf_mat = ConfusionMeter(num_class=2)\n",
    "        i = 0\n",
    "        for stimulus, target in valid_dl:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                decision = model(stimulus)\n",
    "                \n",
    "                pred = decision.clone()\n",
    "\n",
    "                \n",
    "                decision_copy = decision.clone()\n",
    "                pred = target.clone()\n",
    "                idx1 = decision_copy[:,1] < decision_copy[:,0]\n",
    "                idx2 = decision_copy[:,1] >= decision_copy[:,0]\n",
    "                pred[idx1] = 0\n",
    "                pred[idx2] = 1\n",
    "\n",
    "                target_copy = target.squeeze().int()\n",
    "                conf_mat.update(pred.int(),target_copy)\n",
    "                del pred\n",
    "                L = loss(decision, target.squeeze())\n",
    "                Loss_valid += L/len(train_dl)\n",
    "                \n",
    "#                 \n",
    "\n",
    "                del L\n",
    "        if epoch == 0:\n",
    "            conf_mat.print_mat()\n",
    "            \n",
    "        all_loss.append(Loss)\n",
    "        all_loss_valid.append(Loss_valid)\n",
    "        \n",
    "    conf_mat.print_mat()\n",
    "        # print(f'epoch {epoch},   training Loss = {Loss},   validation Loss = {Loss_valid}')\n",
    "    return all_loss, all_loss_valid, model\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========Check Grad============\n",
      "sensory_pop.sensory_neurons_1.linear.weight False\n",
      "sensory_pop.sensory_neurons_1.linear.bias False\n",
      "sensory_pop.sensory_neurons_2.linear.weight False\n",
      "sensory_pop.sensory_neurons_2.linear.bias False\n",
      "readout.readout_layer.weight True\n",
      "readout.readout_layer.bias True\n",
      "=================================\n",
      "\n",
      "Confusion Matrix: (target in columns)\n",
      "[[1000. 1000.]\n",
      " [   0.    0.]]\n",
      "Confusion Matrix: (target in columns)\n",
      "[[1000.  999.]\n",
      " [   0.    1.]]\n",
      "Final train loss = 0.025436002761125565,    valid loss = 8.518227577209473 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "lr = 0.5\n",
    "batch_size = 100\n",
    "\n",
    "loss, loss_valid, model = main(num_epochs = num_epochs, lr = lr, batch_size = batch_size)\n",
    "print(f'Final train loss = {loss[-1]},    valid loss = {loss_valid[-1]} \\n')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(np.arange(0,num_epochs),loss)\n",
    "plt.plot(np.arange(0,num_epochs),loss_valid)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(model.readout.readout_layer.weight.detach())\n",
    "\n",
    "plt.scatter(torch.cat((model.sensory_pop.sensory_neurons_1.linear.weight,model.sensory_pop.sensory_neurons_2.linear.weight),dim=0).detach(),\n",
    "            model.readout.readout_layer.weight[0,:].detach())\n",
    "plt.ylabel('readout weight')\n",
    "plt.xlabel('sigmoid weight')\n",
    "plt.show()\n",
    "# plt.scatter(torch.cat((model.sensory_pop.sensory_neurons_1.linear.bias,model.sensory_pop.sensory_neurons_2.linear.bias),dim=0).detach(),\n",
    "#             model.readout.readout_layer.weight[0,:].detach())\n",
    "# plt.ylabel('readout weight')\n",
    "# plt.xlabel('sigmoid bias')\n",
    "# model.sensory_pop.sensory_neurons_1.linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
